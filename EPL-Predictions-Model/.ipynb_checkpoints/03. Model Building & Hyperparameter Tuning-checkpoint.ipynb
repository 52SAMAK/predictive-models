{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation_functions import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn import linear_model, tree, discriminant_analysis, naive_bayes, ensemble, gaussian_process\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPL Machine Learning Walkthrough\n",
    "\n",
    "## 03. Model Building & Hyperparameter Tuning\n",
    "Welcome to the third part of this Machine Learning Walkthrough. This tutorial will focus on the model building process, including how to tune hyperparameters. In the [next tutorial], we will create weekly predictions based on the model we have created here.\n",
    "\n",
    "Specifically, this tutorial will cover a few things:\n",
    "\n",
    "1. Choosing which Machine Learning algorithm to use from a variety of choices\n",
    "2. Hyperparameter Tuning\n",
    "3. Overfitting/Underfitting\n",
    "\n",
    "### Choosing an Algorithm\n",
    "The best way to decide on specific algorithm to use, is to try them all! To do this, we will define a function which we first used in our AFL Predictions tutorial. This will iterate over a number of algorithms and give us a good indication of which algorithms are suited for this dataset and exercise.\n",
    "\n",
    "Let's first use grab the features we created in the last tutorial. This may take a minute or two to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating all games feature DataFrame\n",
      "Creating stats feature DataFrame\n",
      "Creating odds feature DataFrame\n",
      "Creating market values feature DataFrame\n",
      "Filling NAs\n",
      "Merging stats, odds and market values into one features DataFrame\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "features = create_feature_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start our modelling process, we need to make a training set, a test set and a holdout set. As we are using cross validation, we will make our training set all of the seasons up until 2017/18, and we will use the 2017/18 season as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [col for col in features.columns if col.startswith(\"f_\")]\n",
    "betting_features = []\n",
    "\n",
    "le = LabelEncoder() # Initiate a label encoder to transform the labels 'away', 'draw', 'home' to 0, 1, 2\n",
    "\n",
    "# Grab all seasons except for 17/18 to use CV with\n",
    "all_x = features.loc[features.season != '1718', ['gameId'] + feature_list]\n",
    "all_y = features.loc[features.season != '1718', 'result']\n",
    "all_y = le.fit_transform(all_y)\n",
    "\n",
    "# Create our training vector as the seasons except 16/17 and 17/18\n",
    "train_x = features.loc[~features.season.isin(['1617', '1718']), ['gameId'] + feature_list]\n",
    "train_y = le.transform(features.loc[~features.season.isin(['1617', '1718']), 'result'])\n",
    "\n",
    "# Create our holdout vectors as the 16/17 season\n",
    "holdout_x = features.loc[features.season == '1617', ['gameId'] + feature_list]\n",
    "holdout_y = le.transform(features.loc[features.season == '1617', 'result'])\n",
    "\n",
    "# Create our test vectors as the 17/18 season\n",
    "test_x = features.loc[features.season == '1718', ['gameId'] + feature_list]\n",
    "test_y = le.transform(features.loc[features.season == '1718', 'result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of standard classifiers\n",
    "classifiers = [\n",
    "\n",
    "    #GLM\n",
    "    linear_model.LogisticRegressionCV(),\n",
    "    \n",
    "    #Navies Bayes\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    \n",
    "    #Discriminant Analysis\n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "    #Ensemble Methods\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "\n",
    "    #Gaussian Processes\n",
    "    gaussian_process.GaussianProcessClassifier(),\n",
    "    \n",
    "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "    xgb.XGBClassifier()    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_algorithms(classifier_list, X, y):\n",
    "    # This function is adapted from https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling\n",
    "    # Cross validate model with Kfold stratified cross validation\n",
    "    kfold = StratifiedKFold(n_splits=5)\n",
    "    \n",
    "    # Grab the cross validation scores for each algorithm\n",
    "    cv_results = [cross_val_score(classifier, X, y, scoring = \"neg_log_loss\", cv = kfold) for classifier in classifier_list]\n",
    "    cv_means = [cv_result.mean() * -1 for cv_result in cv_results]\n",
    "    cv_std = [cv_result.std() for cv_result in cv_results]\n",
    "    algorithm_names = [alg.__class__.__name__ for alg in classifiers]\n",
    "    \n",
    "    # Create a DataFrame of all the CV results\n",
    "    cv_results = pd.DataFrame({\n",
    "        \"Mean Log Loss\": cv_means,\n",
    "        \"Log Loss Std\": cv_std,\n",
    "        \"Algorithm\": algorithm_names\n",
    "    }).sort_values(by='Mean Log Loss')\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_results = find_best_algorithms(classifiers, all_x, all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Log Loss</th>\n",
       "      <th>Log Loss Std</th>\n",
       "      <th>Algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.970049</td>\n",
       "      <td>0.011120</td>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.985279</td>\n",
       "      <td>0.013183</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.017280</td>\n",
       "      <td>0.011409</td>\n",
       "      <td>BernoulliNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.120555</td>\n",
       "      <td>0.054798</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.185451</td>\n",
       "      <td>0.229987</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.191578</td>\n",
       "      <td>0.212869</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.964932</td>\n",
       "      <td>0.168254</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.146797</td>\n",
       "      <td>0.216481</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.192145</td>\n",
       "      <td>0.206751</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.994579</td>\n",
       "      <td>1.105408</td>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.105398</td>\n",
       "      <td>0.485291</td>\n",
       "      <td>GaussianNB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mean Log Loss  Log Loss Std                      Algorithm\n",
       "0        0.970049      0.011120           LogisticRegressionCV\n",
       "3        0.985279      0.013183     LinearDiscriminantAnalysis\n",
       "1        1.017280      0.011409                    BernoulliNB\n",
       "10       1.098612      0.000000      GaussianProcessClassifier\n",
       "5        1.120555      0.054798             AdaBoostClassifier\n",
       "11       1.185451      0.229987                  XGBClassifier\n",
       "8        1.191578      0.212869     GradientBoostingClassifier\n",
       "9        1.964932      0.168254         RandomForestClassifier\n",
       "6        2.146797      0.216481              BaggingClassifier\n",
       "7        2.192145      0.206751           ExtraTreesClassifier\n",
       "4        3.994579      1.105408  QuadraticDiscriminantAnalysis\n",
       "2        5.105398      0.485291                     GaussianNB"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that LogisticRegression seems to perform the best out of all the algorithms, and some algorithms have a very high log loss. This is most likely due to overfitting. It would definitely be useful to condense our features down to reduce the dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "For now, however, we will use logistic regression. Let's first try and tune a logistic regression model with cross validation. To do this, we will use [grid search](https://en.wikipedia.org/wiki/Hyperparameter_optimization). Grid search essentially tries out each combination of values and finds the model with the lowest error metric, which in our case is log loss. 'C' in logistic regression determines the amount of regularization. Lower values increase regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best log loss: 0.9691398446526489\n"
     ]
    }
   ],
   "source": [
    "# Define our parameters to run a grid search over\n",
    "lr_grid = {\n",
    "    \"C\": [0.0001, 0.01, 0.05, 0.2, 1],\n",
    "    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "}\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "gs = GridSearchCV(LogisticRegression(), param_grid=lr_grid, cv=kfold, scoring='neg_log_loss')\n",
    "gs.fit(all_x, all_y)\n",
    "print(\"Best log loss: {}\".format(gs.best_score_ *-1))\n",
    "best_lr_params = gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Baseline\n",
    "We should also define a baseline, as we don't really know if our log loss is good or bad. Randomly assigning a 1/3 chance to each selection yields a log loss of log3 = 1.09. However, what we are really interested in, is how our model performs relative to the odds. So let's find the log loss of the odds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9602891549225175"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the log loss of the odds\n",
    "log_loss(all_y, 1 / all_x[['f_awayOdds', 'f_drawOdds', 'f_homeOdds']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good news; our algorithm almost beats the bookies in terms of log loss. It would be great if we could beat this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the Errors Made\n",
    "Now that we have a logistic regression model tuned, let's see what type of errors it made. To do this we will look at the confusion matrix produced when we predict our holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(**best_lr_params) # Instantiate the model\n",
    "lr.fit(train_x, train_y) # Fit our model\n",
    "lr_predict = lr.predict(holdout_x) # Predict the holdout values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>away</th>\n",
       "      <th>draw</th>\n",
       "      <th>home</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>away</th>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>draw</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home</th>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  away  draw  home\n",
       "Actual                     \n",
       "away         79     2    28\n",
       "draw         24     6    54\n",
       "home         35     6   146"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "c_matrix = (pd.DataFrame(confusion_matrix(holdout_y, lr_predict), columns=le.classes_, index=le.classes_)\n",
    " .rename_axis('Actual')\n",
    " .rename_axis('Predicted', axis='columns'))\n",
    "\n",
    "c_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, when we predicted 'away' as the result, we correctly predicted 79 / 109 results, a hit rate of 70.6%. However, when we look at our draw hit rate, we only predicted 6 / 84 correctly, meaning we only had a hit rate of around 8.3%. For a more in depth analysis of our predictions, please skip to the Analysing Predictions & Staking Strategies section of the tutorial.\n",
    "\n",
    "Before we move on, however, let's use our model to predict the 17/18 season and compare how we went with the odds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our predictions for the 2017/18 season have a log loss of: 0.95872 and an accuracy of: 0.54\n"
     ]
    }
   ],
   "source": [
    "# Get test predictions\n",
    "\n",
    "test_lr = LogisticRegression(**best_lr_params)\n",
    "test_lr.fit(all_x, all_y)\n",
    "test_predictions_probs = lr.predict_proba(test_x)\n",
    "test_predictions = lr.predict(test_x)\n",
    "\n",
    "test_ll = log_loss(test_y, test_predictions_probs)\n",
    "test_accuracy = (test_predictions == test_y).mean()\n",
    "\n",
    "print(\"Our predictions for the 2017/18 season have a log loss of: {0:.5f} and an accuracy of: {1:.2f}\".format(test_ll, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odds predictions for the 2017/18 season have a log loss of: 0.94635 and an accuracy of: 0.545\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy and log loss based on the odds\n",
    "odds_ll = log_loss(test_y, 1 / test_x[['f_awayOdds', 'f_drawOdds', 'f_homeOdds']])\n",
    "\n",
    "odds_predictions = test_x[['f_awayOdds', 'f_drawOdds', 'f_homeOdds']].apply(lambda row: row.idxmin()[2:6], axis=1).values\n",
    "odds_accuracy = (odds_predictions == le.inverse_transform(test_y)).mean()\n",
    "\n",
    "print(\"Odds predictions for the 2017/18 season have a log loss of: {0:.5f} and an accuracy of: {1:.3f}\".format(odds_ll, odds_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "There we have it! The odds predicted 54.5% of EPL games correctly in the 2017/18 season, whilst our model predicted 54% correctly. This is a decent result for the first iteration of our model. In future iterations, we could wait a certain number of matches each season and calculate EMAs for on those first n games. This may help the issue of players switching clubs and teams becoming relatively stronger/weaker compared to previous seasons."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
