{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFL Model - Part 3 - Modelling\n",
    "\n",
    "These tutorials will walk you through how to construct your own basic AFL model, using publically available data. The output will be odds for each team to win, which will be shown on [The Hub](https://www.betfair.com.au/hub/tools/models/afl-prediction-model/).\n",
    "\n",
    "In this notebook we will walk you through modelling our AFL data to create predictions. We will train a variety of quick and easy models to get a feel of what works and what doesn't. We will then tune our hyperparameters so that we are ready to make week by week predictions.\n",
    "\n",
    "## Grabbing Our Dataset\n",
    "First, we will import our required modules, as well as the prepare_afl_features function which we created in our afl_feature_creation script. This essentially creates some basic features for us so that we can get started on the modelling component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from afl_feature_creation import prepare_afl_features\n",
    "import afl_feature_creation\n",
    "import afl_data_cleaning\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from afl_data_cleaning import prepare_afl_data\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import RFECV\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn import feature_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab our feature DataFrame which we created in the previous tutorial\n",
    "feature_df = afl_feature_creation.prepare_afl_features(window=6, k_factor=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will need to get our data onto individual rows for each game, rather than split on two rows like it is currently. We will create a function to do this merging for us, and then another function which subtracts the away stats from the home stats, so we reduce the amount of columns that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_on_one_line(df):\n",
    "    cols_to_drop = ['Team', 'Date', 'home_team', 'away_team', 'Home?', 'Opposition', 'Opposition Behinds', 'Opposition Goals', \n",
    "    'Opposition Points', 'Points', 'Round', 'Venue', 'Season', 'Status']\n",
    "    \n",
    "    # Create a home and away team DataFrame to then allow us to put each game onto individual rows\n",
    "    home_df = df[df['Home?'] == 1]\n",
    "    away_df = df[df['Home?'] == 0]\n",
    "    away_df = away_df.drop(columns=cols_to_drop)\n",
    "    home_df = home_df.drop(columns=['Team', 'Home?'])\n",
    "\n",
    "    # Rename away_df columns\n",
    "    away_df_renamed = away_df.rename(columns={col: col + '_away' for col in away_df.columns if col != 'Game'})\n",
    "    merged_df = pd.merge(home_df, away_df_renamed, on='Game')\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our function\n",
    "afl_with_NaNs = get_df_on_one_line(feature_df)\n",
    "\n",
    "# Drop NA rows which were a result of calculating rolling averages\n",
    "afl = afl_with_NaNs.dropna().sort_values(by='Game')\n",
    "\n",
    "# Drop columns which leak data and which we don't need\n",
    "dropped_cols = ['Behinds', 'Goals', 'Opposition Behinds', 'Opposition Goals', 'Opposition Points', 'Points',\n",
    "               'Behinds_away', 'Goals_away', 'home_win_away', 'home_elo_away', 'away_elo_away', 'elo', 'elo_Opp', 'CCL_ave_6', \n",
    "                'SCL_ave_6', 'SI_ave_6', 'MG_ave_6', 'TO_ave_6', 'ITC_ave_6', 'T5_ave_6', 'CCL_ave_6_away', 'SCL_ave_6_away',\n",
    "               'SI_ave_6_away', 'MG_ave_6_away', 'TO_ave_6_away', 'ITC_ave_6_away', 'T5_ave_6_away', 'elo_away', 'elo_Opp_away']\n",
    "afl = afl.drop(columns=dropped_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create a 'differential DataFrame' which essentially just subtracts the away teams' features from the home teams'. This will reduce the huge amount of columns we have and make our data more manageable. To do this, we will need a list of columns which we are subtracting from each other. We will then loop over each of these columns to create our new differential columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of columns which we are subtracting from each other\n",
    "cols = [col for col in afl.columns if col + '_away' in afl.columns and col != 'odds']\n",
    "\n",
    "diff_df = afl.copy()\n",
    "diff_cols = [col + '_diff' for col in cols]\n",
    "\n",
    "for col in cols:\n",
    "    diff_df[col + '_diff'] = afl[col] - afl[col + '_away']\n",
    "    diff_df = diff_df.drop(columns=[col, col + '_away'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create an implied odds feature from the odds. Some Machine Learning algorithms perform better if the features used are normally distributed, so we will try and normalise our odds slightly by finding the implied probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an implied odds feature\n",
    "diff_df['implied_odds_prob'] = 1 / diff_df['odds']\n",
    "diff_df['implied_odds_prob_away'] = 1 / diff_df['odds']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Training and Testing Set\n",
    "So that we don't train our data on the data that we will later test our model on, we will create separate train and test sets. For this exercise we will use the 2018 season to test how our model performs, whilst the rest of the data can be used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our test and train sets from our afl DataFrame; drop the columns which leak the result, duplicates, and the advanced\n",
    "# stats which don't have data until 2015\n",
    "\n",
    "# Create our test set\n",
    "test_x = diff_df[diff_df['Season'] == 2018].drop(columns=['home_win', 'odds', 'odds_away']).select_dtypes(include=[np.number])\n",
    "test_y = diff_df[diff_df['Season'] == 2018]['home_win']\n",
    "\n",
    "# Create our train sets\n",
    "X = diff_df[diff_df['Season'] != 2018].drop(columns=['home_win', 'odds', 'odds_away']).select_dtypes(include=[np.number])\n",
    "y = diff_df[diff_df['Season'] != 2018]['home_win']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Cross Validation to Find The Best Algorithms\n",
    "Now that we have our training set, we can run through a list of popular classifiers to determine which classifier is best for modelling our data. To do this we will create a function which uses Kfold cross-validation to find the 'best' algorithms, based on how accurate the algorithms' predictions are.\n",
    "\n",
    "This function will take in a list of classifiers, which we will define below, as well as the training set and it's outcome, and output a DataFrame with the mean and std of the accuracy of each algorithm. Let's jump into it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of standard classifiers\n",
    "classifiers = [\n",
    "    #Ensemble Methods\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "\n",
    "    #Gaussian Processes\n",
    "    gaussian_process.GaussianProcessClassifier(),\n",
    "    \n",
    "    #GLM\n",
    "    linear_model.LogisticRegressionCV(),\n",
    "    linear_model.PassiveAggressiveClassifier(),\n",
    "    linear_model.RidgeClassifierCV(),\n",
    "    linear_model.SGDClassifier(),\n",
    "    linear_model.Perceptron(),\n",
    "    \n",
    "    #Navies Bayes\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    \n",
    "    #Nearest Neighbor\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    \n",
    "    #SVM\n",
    "    svm.SVC(probability=True),\n",
    "    svm.NuSVC(probability=True),\n",
    "    svm.LinearSVC(),\n",
    "    \n",
    "    #Trees    \n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.ExtraTreeClassifier(),\n",
    "    \n",
    "    #Discriminant Analysis\n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "    \n",
    "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "    XGBClassifier()    \n",
    "]\n",
    "\n",
    "# Define a functiom which finds the best algorithms for our modelling task\n",
    "def find_best_algorithms(classifier_list, X, y):\n",
    "    # This function is adapted from https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling\n",
    "    # Cross validate model with Kfold stratified cross validation\n",
    "    kfold = StratifiedKFold(n_splits=5)\n",
    "    \n",
    "    # Grab the cross validation scores for each algorithm\n",
    "    cv_results = [cross_val_score(classifier, X, y, scoring = \"accuracy\", cv = kfold) for classifier in classifier_list]\n",
    "    cv_means = [cv_result.mean() for cv_result in cv_results]\n",
    "    cv_std = [cv_result.std() for cv_result in cv_results]\n",
    "    algorithm_names = [alg.__class__.__name__ for alg in classifiers]\n",
    "    \n",
    "    # Create a DataFrame of all the CV results\n",
    "    cv_results = pd.DataFrame({\n",
    "        \"Mean Accuracy\": cv_means,\n",
    "        \"Accuracy Std\": cv_std,\n",
    "        \"Algorithm\": algorithms\n",
    "    })\n",
    "    \n",
    "    \n",
    "    # Create a plot showing the best cross_validation scores\n",
    "    g = sns.barplot(\"Mean Accuracy\", \"Algorithm\", data = cv_results.sort_values(by='Mean Accuracy'), palette=\"Set3\", orient = \"h\", **{'xerr': cv_std})\n",
    "    g.set_xlabel(\"Mean Accuracy\")\n",
    "    g = g.set_title(\"Cross Validation Scores\")\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a40d7fab70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_algos = find_best_algorithms(classifiers, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing Our Algorithms\n",
    "As we can see from above, there are some pretty poor algorithms for predicting the winner. On the other hand, whilst attaining an accuracy of 70% may seem like a decent result; we must first establish a baseline to judge our performance on. In this case, we will have two baselines; the proportion of games won by the home team and what the odds predict. If we can beat the odds we have created a very powerful model.\n",
    "\n",
    "Once we establish our baseline, we will choose the top algorithms from above and tune their hyperparameters, as well as automatically selecting the best features to be used in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Our Baseline\n",
    "As stated above, we must define our baseline so that we have a measure to beat. We will use the proportion of games won by the home team, as well as the proportion of favourites who won, based off the odds. To establish this baseline we will use our feature_df, as this has no dropped rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_win</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0.566327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>0.567568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>0.570652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>0.580488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.548544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.619565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.608040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        home_win\n",
       "Season          \n",
       "2011    0.566327\n",
       "2012    0.567568\n",
       "2013    0.570652\n",
       "2014    0.580488\n",
       "2015    0.548544\n",
       "2016    0.619565\n",
       "2017    0.608040\n",
       "2018    0.545455"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the percentage chance of winning at home in each season.\n",
    "afl_data = prepare_afl_data()\n",
    "afl_data['home_win'] = afl_data.apply(lambda x: 1 if x['Margin'] > 0 else 0, axis=1)\n",
    "home_games = afl_data[afl_data['Home?'] == 1]\n",
    "home_games[[\"home_win\", 'Season']].groupby(['Season']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall mean accuracy of choosing the favourite based on the odds is 71.61%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>odds_prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0.780612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>0.745946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>0.706522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>0.717073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.718447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.690217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.648241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        odds_prediction\n",
       "Season                 \n",
       "2011           0.780612\n",
       "2012           0.745946\n",
       "2013           0.706522\n",
       "2014           0.717073\n",
       "2015           0.718447\n",
       "2016           0.690217\n",
       "2017           0.648241\n",
       "2018           0.727273"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the proportion of favourites who have won\n",
    "\n",
    "# Define a function which finds if the odds correctly guessed the response\n",
    "def find_odds_prediction(a_row):\n",
    "    if a_row['odds'] <= a_row['odds_away'] and a_row['home_win'] == 1:\n",
    "        return 1\n",
    "    elif a_row['odds_away'] < a_row['odds'] and a_row['home_win'] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "afl_data_one_line = get_df_on_one_line(afl_data)\n",
    "afl_data_one_line['odds_prediction'] = afl_data_one_line.apply(find_odds_prediction, axis=1)\n",
    "print('The overall mean accuracy of choosing the favourite based on the odds is {}%'.format(\n",
    "    round(afl_data_one_line['odds_prediction'].mean() * 100, 2)))\n",
    "afl_data_one_line[[\"odds_prediction\", 'Season']].groupby(['Season']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the odds are MUCH more accurate than just choosing the home team to win. We can also see that the mean accuracy of choosing the favourite is around 72%. That means that this is the score we need to beat. So let's choose all the algorithms which get a better score than 65% to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy Std</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037842</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.654108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.025462</td>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>0.674817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.016388</td>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>0.706386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.043408</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.675689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.012530</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.708196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy Std                   Algorithm  Mean Accuracy\n",
       "4       0.037842      RandomForestClassifier       0.654108\n",
       "6       0.025462        LogisticRegressionCV       0.674817\n",
       "8       0.016388           RidgeClassifierCV       0.706386\n",
       "12      0.043408                  GaussianNB       0.675689\n",
       "19      0.012530  LinearDiscriminantAnalysis       0.708196"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_algorithms = best_algos[best_algos['Mean Accuracy'] > 0.65]['Algorithm'].tolist()\n",
    "best_algos[best_algos['Mean Accuracy'] > 0.65]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Grid Search To Tune Hyperparameters\n",
    "Now that we have our best models, we can use [Grid Search](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search) to optimise our hyperparameters. Grid search basically involves searching through a range of different algorithm hyperparameters, and choosing those which result in the best score from some metrics, which in our case is accuracy. Let's do this for the algorithms which have hyperparameters which can be tuned. Note that if you are running this on your own computer it may take up to 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function which optimises the hyperparameters of our chosen algorithms\n",
    "def optimise_hyperparameters(train_x, train_y, algorithms, parameters):\n",
    "    kfold = StratifiedKFold(n_splits=5)\n",
    "    best_estimators = []\n",
    "    \n",
    "    for alg, params in zip(algorithms, parameters):\n",
    "        gs = GridSearchCV(alg, param_grid=params, cv=kfold)\n",
    "        gs.fit(train_x, train_y)\n",
    "        best_estimators.append(gs.best_estimator_)\n",
    "    return best_estimators\n",
    "\n",
    "# Define our parameters to run a grid search over\n",
    "lr_grid = {\n",
    "    \"C\": [0.05, 0.2, 0.5, 0.75, 0.85, 1, 1.1, 1.2, 2],\n",
    "    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "}\n",
    "\n",
    "ridge_grid = {'alpha': [1.0, 2.5, 5.0, 10.0]}\n",
    "\n",
    "rf_grid = {\n",
    "    \"max_depth\": [10, 15],\n",
    "    \"min_samples_split\": [2, 10],\n",
    "    \"min_samples_leaf\": [1, 20],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "# Add our algorithms and parameters to lists to be used in our function\n",
    "alg_list = [LogisticRegression(), RidgeClassifier(), RandomForestClassifier(n_estimators=750, random_state=5, n_jobs=-1)]\n",
    "param_list = [lr_grid, ridge_grid, rf_grid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best estimators, then add our other estimators which don't need optimisation\n",
    "best_estimators = optimise_hyperparameters(X, y, alg_list, param_list)\n",
    "all_estimators = best_estimators + [GaussianNB(), LinearDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a list of all the estimators we are going to use, with optimised hyperparameters. Our next step is to choose our features, and then we will create a stacked model using the estimators we just chose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Recursive Feature Elimination with Cross Validation to Select Features\n",
    "Now that we have our model's hyperparameters tuned, we can focus on feature selection. Here, we will use Recursive Feature Elimination Cross Validation, which trains a specified model using cross-validation and recursively eliminates features until the model doesn't improve. We will use a Random Forest Classifier for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X, y, estimator):\n",
    "    # Remove non-numeric columns\n",
    "    X = X.select_dtypes([np.number])\n",
    "    \n",
    "    clf = estimator\n",
    "    selector = RFECV(clf, cv=10, scoring='accuracy')\n",
    "    selector.fit(X, y)\n",
    "    \n",
    "    best_columns = list(X.columns[selector.support_])\n",
    "    return best_columns\n",
    "\n",
    "best_cols = select_features(X.drop(columns=['Game', 'Round', 'Season']), y, RandomForestClassifier(random_state=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! now we have tuned our model and chosen our features. Let's have a look at the features that we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['home_elo',\n",
       " 'away_elo',\n",
       " 'GA_ave_6_diff',\n",
       " 'CP_ave_6_diff',\n",
       " 'UP_ave_6_diff',\n",
       " 'ED_ave_6_diff',\n",
       " 'CM_ave_6_diff',\n",
       " 'MI5_ave_6_diff',\n",
       " 'One.Percenters_ave_6_diff',\n",
       " 'BO_ave_6_diff',\n",
       " 'HB_ave_6_diff',\n",
       " 'M_ave_6_diff',\n",
       " 'G_ave_6_diff',\n",
       " 'T_ave_6_diff',\n",
       " 'HO_ave_6_diff',\n",
       " 'I50_ave_6_diff',\n",
       " 'CL_ave_6_diff',\n",
       " 'CG_ave_6_diff',\n",
       " 'R50_ave_6_diff',\n",
       " 'FF_ave_6_diff',\n",
       " 'FA_ave_6_diff',\n",
       " 'AF_ave_6_diff',\n",
       " 'SC_ave_6_diff',\n",
       " 'disposal_efficiency_ave_6_diff',\n",
       " 'R50_efficiency_ave_6_diff',\n",
       " 'I50_efficiency_ave_6_diff',\n",
       " 'Adj_elo_ave_margin_ave_6_diff',\n",
       " 'average_elo_opponents_beaten_6_diff',\n",
       " 'average_elo_opponents_lost_6_diff',\n",
       " 'Margin_ave_6_diff',\n",
       " 'implied_odds_prob',\n",
       " 'implied_odds_prob_away']"
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Our Models To Create A Strong Learner\n",
    "A popular way to improve the accuracy of our individual models is to combine them together to create a strong learner. We are going to implement Stacking, which is an ensemble method which introduces the concept of a 'meta-learner'. Essentially, we use half of our training data to train a number of different classifiers, known as base-learners. In our case, these classifiers will be the ones which had an accuracy of 65% or greater. We then use these trained classifiers to predict the values of the other half of our training data. These predictions are known as base-predictions. We then use these predictions as the training data for a final classifier (we will use XGB), which we call a 'meta-leaner'.\n",
    "\n",
    "To predict our final results all we need to do is feed our test data to the base learners which result in base-predictions, which we then feed to our meta-learner to predict our test labels.\n",
    "\n",
    "I hope you got your head around that! Below is a diagram, taken from [this](http://supunsetunga.blogspot.com/2016/06/stacking-in-machine-learning.html?_sm_au_=iVVQP1LFpFrpsRqj) blog which depicts the process nicely.\n",
    "\n",
    "![caption](Images/Stacking.png)\n",
    "\n",
    "Let's now define a function which creates this strong learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implement_xgb_stacking(train_x, train_y, test_x, classifier_list):\n",
    "    # Get half of the DataFrame to train the base learners on and the other half to create base predictions\n",
    "    xtrain_base, xpred_base, ytrain_base, ypred_base = train_test_split(train_x, train_y, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Create two DataFrames - one for our base predictions to train the meta-learner and the other to be used \n",
    "    # for the meta-learner's predictions\n",
    "    base_df = pd.DataFrame()\n",
    "    test_base_df = pd.DataFrame()\n",
    "    \n",
    "    # Loop over the classifiers to train the base-learners\n",
    "    for clf in classifier_list:\n",
    "        # Fit each classifier using the base training data\n",
    "        clf.fit(xtrain_base, ytrain_base)\n",
    "        \n",
    "        # Create a base predictions DataFrame to be used to train the meta-learner\n",
    "        base_preds = clf.predict(xpred_base)\n",
    "        base_df[clf.__class__.__name__] = base_preds\n",
    "        \n",
    "        # Use the base learners to create test_predictions to be used for our final meta-learner predictions\n",
    "        test_preds = clf.predict(test_x)\n",
    "        test_base_df[clf.__class__.__name__] = test_preds\n",
    "\n",
    "    meta_clf = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0.25, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=10, min_child_weight=1, missing=None, n_estimators=100,\n",
    "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=1, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)\n",
    "    \n",
    "    # Train the meta-learner\n",
    "    meta_clf.fit(base_df, ypred_base)\n",
    "    \n",
    "    # Predict\n",
    "    final_preds = meta_clf.predict(test_base_df)\n",
    "    return final_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Our Model On the Test Set\n",
    "Finally, we are ready to test our model on the test set, to see how accurate it was. Remember, the test set in this case is the 2018 season. The goal is to predict more footy games correctly than just choosing the favourite (which had an accuracy of 72% so far in 2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = implement_xgb_stacking(X[best_cols], y, test_x[best_cols], all_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy in predicting the 2018 season is: 74.54545454545455%\n"
     ]
    }
   ],
   "source": [
    "accuracy = (final_predictions == test_y).mean() * 100\n",
    "\n",
    "print(\"Our accuracy in predicting the 2018 season is: {}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! We have predicted more results correctly than the odds. Let's now inspect our errors to see the games which we got wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>odds</th>\n",
       "      <th>odds_away</th>\n",
       "      <th>home_win</th>\n",
       "      <th>home_elo</th>\n",
       "      <th>away_elo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>Essendon</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>1.8628</td>\n",
       "      <td>2.1393</td>\n",
       "      <td>1</td>\n",
       "      <td>1467.506321</td>\n",
       "      <td>1646.687609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>Gold Coast</td>\n",
       "      <td>North Melbourne</td>\n",
       "      <td>2.0161</td>\n",
       "      <td>1.9784</td>\n",
       "      <td>1</td>\n",
       "      <td>1300.806887</td>\n",
       "      <td>1410.870164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Geelong</td>\n",
       "      <td>1.7737</td>\n",
       "      <td>2.2755</td>\n",
       "      <td>0</td>\n",
       "      <td>1454.806809</td>\n",
       "      <td>1703.083537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>1.8478</td>\n",
       "      <td>2.1784</td>\n",
       "      <td>1</td>\n",
       "      <td>1628.994882</td>\n",
       "      <td>1567.420082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>North Melbourne</td>\n",
       "      <td>St Kilda</td>\n",
       "      <td>3.5769</td>\n",
       "      <td>1.3867</td>\n",
       "      <td>1</td>\n",
       "      <td>1395.190972</td>\n",
       "      <td>1466.363057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>Carlton</td>\n",
       "      <td>Gold Coast</td>\n",
       "      <td>1.5992</td>\n",
       "      <td>2.6620</td>\n",
       "      <td>0</td>\n",
       "      <td>1327.788050</td>\n",
       "      <td>1316.486079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>Collingwood</td>\n",
       "      <td>GWS</td>\n",
       "      <td>3.0799</td>\n",
       "      <td>1.4819</td>\n",
       "      <td>0</td>\n",
       "      <td>1459.342451</td>\n",
       "      <td>1597.573405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>Fremantle</td>\n",
       "      <td>Essendon</td>\n",
       "      <td>2.6997</td>\n",
       "      <td>1.5939</td>\n",
       "      <td>1</td>\n",
       "      <td>1425.806319</td>\n",
       "      <td>1485.199049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>Port Adelaide</td>\n",
       "      <td>1.4949</td>\n",
       "      <td>3.0060</td>\n",
       "      <td>0</td>\n",
       "      <td>1678.762837</td>\n",
       "      <td>1556.637984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>Geelong</td>\n",
       "      <td>Hawthorn</td>\n",
       "      <td>1.7597</td>\n",
       "      <td>2.3024</td>\n",
       "      <td>0</td>\n",
       "      <td>1707.720913</td>\n",
       "      <td>1620.201973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Collingwood</td>\n",
       "      <td>1.2048</td>\n",
       "      <td>5.9197</td>\n",
       "      <td>0</td>\n",
       "      <td>1644.991667</td>\n",
       "      <td>1459.394319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>Essendon</td>\n",
       "      <td>Port Adelaide</td>\n",
       "      <td>2.3180</td>\n",
       "      <td>1.7486</td>\n",
       "      <td>1</td>\n",
       "      <td>1459.799605</td>\n",
       "      <td>1576.018468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>1.2640</td>\n",
       "      <td>4.6929</td>\n",
       "      <td>0</td>\n",
       "      <td>1679.241033</td>\n",
       "      <td>1627.128719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>2.7929</td>\n",
       "      <td>1.5556</td>\n",
       "      <td>0</td>\n",
       "      <td>1459.618034</td>\n",
       "      <td>1575.444609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>Western Bulldogs</td>\n",
       "      <td>Carlton</td>\n",
       "      <td>1.4867</td>\n",
       "      <td>3.0356</td>\n",
       "      <td>1</td>\n",
       "      <td>1480.519530</td>\n",
       "      <td>1295.107441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>Geelong</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>1.5019</td>\n",
       "      <td>2.9833</td>\n",
       "      <td>0</td>\n",
       "      <td>1689.544561</td>\n",
       "      <td>1665.454514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>Collingwood</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>3.0176</td>\n",
       "      <td>1.4902</td>\n",
       "      <td>0</td>\n",
       "      <td>1489.202458</td>\n",
       "      <td>1583.586000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>Western Bulldogs</td>\n",
       "      <td>Gold Coast</td>\n",
       "      <td>1.2741</td>\n",
       "      <td>4.5799</td>\n",
       "      <td>1</td>\n",
       "      <td>1486.661454</td>\n",
       "      <td>1322.549039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>North Melbourne</td>\n",
       "      <td>1.2777</td>\n",
       "      <td>4.5690</td>\n",
       "      <td>0</td>\n",
       "      <td>1678.285224</td>\n",
       "      <td>1418.991203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>Hawthorn</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>1.6280</td>\n",
       "      <td>2.5803</td>\n",
       "      <td>0</td>\n",
       "      <td>1622.292153</td>\n",
       "      <td>1658.689929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>GWS</td>\n",
       "      <td>West Coast</td>\n",
       "      <td>1.5431</td>\n",
       "      <td>2.8255</td>\n",
       "      <td>0</td>\n",
       "      <td>1590.342026</td>\n",
       "      <td>1608.101561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>Port Adelaide</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2.1877</td>\n",
       "      <td>1.8117</td>\n",
       "      <td>1</td>\n",
       "      <td>1549.313729</td>\n",
       "      <td>1647.029554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>Essendon</td>\n",
       "      <td>Geelong</td>\n",
       "      <td>5.6591</td>\n",
       "      <td>1.2098</td>\n",
       "      <td>1</td>\n",
       "      <td>1427.467885</td>\n",
       "      <td>1691.838783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Hawthorn</td>\n",
       "      <td>3.2919</td>\n",
       "      <td>1.4315</td>\n",
       "      <td>1</td>\n",
       "      <td>1227.302282</td>\n",
       "      <td>1611.544709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>GWS</td>\n",
       "      <td>Essendon</td>\n",
       "      <td>1.4346</td>\n",
       "      <td>3.2701</td>\n",
       "      <td>0</td>\n",
       "      <td>1562.155424</td>\n",
       "      <td>1447.167312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>Hawthorn</td>\n",
       "      <td>West Coast</td>\n",
       "      <td>2.2103</td>\n",
       "      <td>1.8132</td>\n",
       "      <td>0</td>\n",
       "      <td>1589.913244</td>\n",
       "      <td>1631.039103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>GWS</td>\n",
       "      <td>1.3237</td>\n",
       "      <td>4.0167</td>\n",
       "      <td>0</td>\n",
       "      <td>1622.416168</td>\n",
       "      <td>1546.322801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>Fremantle</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>4.2942</td>\n",
       "      <td>1.2967</td>\n",
       "      <td>1</td>\n",
       "      <td>1424.570652</td>\n",
       "      <td>1607.829228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Collingwood</td>\n",
       "      <td>1.6039</td>\n",
       "      <td>2.6448</td>\n",
       "      <td>0</td>\n",
       "      <td>1516.210791</td>\n",
       "      <td>1510.972714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>Geelong</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>2.6184</td>\n",
       "      <td>1.6145</td>\n",
       "      <td>0</td>\n",
       "      <td>1682.657509</td>\n",
       "      <td>1594.703066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             home_team        away_team    odds  odds_away  home_win  \\\n",
       "1360          Essendon         Adelaide  1.8628     2.1393         1   \n",
       "1364        Gold Coast  North Melbourne  2.0161     1.9784         1   \n",
       "1365         Melbourne          Geelong  1.7737     2.2755         0   \n",
       "1367          Adelaide         Richmond  1.8478     2.1784         1   \n",
       "1368   North Melbourne         St Kilda  3.5769     1.3867         1   \n",
       "1369           Carlton       Gold Coast  1.5992     2.6620         0   \n",
       "1370       Collingwood              GWS  3.0799     1.4819         0   \n",
       "1372         Fremantle         Essendon  2.6997     1.5939         1   \n",
       "1374            Sydney    Port Adelaide  1.4949     3.0060         0   \n",
       "1375           Geelong         Hawthorn  1.7597     2.3024         0   \n",
       "1385          Adelaide      Collingwood  1.2048     5.9197         0   \n",
       "1391          Essendon    Port Adelaide  2.3180     1.7486         1   \n",
       "1394            Sydney         Adelaide  1.2640     4.6929         0   \n",
       "1401         Melbourne         Richmond  2.7929     1.5556         0   \n",
       "1403  Western Bulldogs          Carlton  1.4867     3.0356         1   \n",
       "1404           Geelong           Sydney  1.5019     2.9833         0   \n",
       "1410       Collingwood         Richmond  3.0176     1.4902         0   \n",
       "1413  Western Bulldogs       Gold Coast  1.2741     4.5799         1   \n",
       "1416            Sydney  North Melbourne  1.2777     4.5690         0   \n",
       "1421          Hawthorn           Sydney  1.6280     2.5803         0   \n",
       "1422               GWS       West Coast  1.5431     2.8255         0   \n",
       "1425     Port Adelaide         Adelaide  2.1877     1.8117         1   \n",
       "1433          Essendon          Geelong  5.6591     1.2098         1   \n",
       "1437          Brisbane         Hawthorn  3.2919     1.4315         1   \n",
       "1443               GWS         Essendon  1.4346     3.2701         0   \n",
       "1444          Hawthorn       West Coast  2.2103     1.8132         0   \n",
       "1455          Adelaide              GWS  1.3237     4.0167         0   \n",
       "1461         Fremantle         Adelaide  4.2942     1.2967         1   \n",
       "1462         Melbourne      Collingwood  1.6039     2.6448         0   \n",
       "1468           Geelong         Richmond  2.6184     1.6145         0   \n",
       "\n",
       "         home_elo     away_elo  \n",
       "1360  1467.506321  1646.687609  \n",
       "1364  1300.806887  1410.870164  \n",
       "1365  1454.806809  1703.083537  \n",
       "1367  1628.994882  1567.420082  \n",
       "1368  1395.190972  1466.363057  \n",
       "1369  1327.788050  1316.486079  \n",
       "1370  1459.342451  1597.573405  \n",
       "1372  1425.806319  1485.199049  \n",
       "1374  1678.762837  1556.637984  \n",
       "1375  1707.720913  1620.201973  \n",
       "1385  1644.991667  1459.394319  \n",
       "1391  1459.799605  1576.018468  \n",
       "1394  1679.241033  1627.128719  \n",
       "1401  1459.618034  1575.444609  \n",
       "1403  1480.519530  1295.107441  \n",
       "1404  1689.544561  1665.454514  \n",
       "1410  1489.202458  1583.586000  \n",
       "1413  1486.661454  1322.549039  \n",
       "1416  1678.285224  1418.991203  \n",
       "1421  1622.292153  1658.689929  \n",
       "1422  1590.342026  1608.101561  \n",
       "1425  1549.313729  1647.029554  \n",
       "1433  1427.467885  1691.838783  \n",
       "1437  1227.302282  1611.544709  \n",
       "1443  1562.155424  1447.167312  \n",
       "1444  1589.913244  1631.039103  \n",
       "1455  1622.416168  1546.322801  \n",
       "1461  1424.570652  1607.829228  \n",
       "1462  1516.210791  1510.972714  \n",
       "1468  1682.657509  1594.703066  "
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_index = test_x.index[(final_predictions != test_y)]\n",
    "afl.loc[preds_index][['home_team', 'away_team', 'odds', 'odds_away', 'home_win', 'home_elo', 'away_elo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very interesting! Most of the games we got wrong were upsets. The model also seems to be picking against Richmond frequently against high quality teams like Adelaide and Geelong - despite Richmond being favourites and winning the 2017 premiership. This is most likely due to Richmond's low elo, and perhaps their game style resulting in less 'favourable' statistics according to our model. This is something we can improve upon in further iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "Now that we have a model up and running, the next steps are to implement the model on a week to week basis. In the next tutorial we will be predicting the upcoming round of footy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
